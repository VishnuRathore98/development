# We can run a whole bunch of docker commands and specify the options, params and images
# that we want to run manually, to automate all of these steps of creating images from
# dockerfiles, building containers using those images and many more we can use 
# docker-compose.
# We can create multiple containers all at once and tear them down when not needed all 
# at once, using a single command.

# Defining docker-compose version to use for specific features, if we dont mention this 
# it will use the most recent version by default.
version: "3"

# Now we will define a service, which is a docker container we want to work on, so if we
# want docker-compose to spin up a container we define a service. If we want docker-compose
# to spin up 4 containers we define 4 services.
services:

  # name of the service
  backend_apis:
    # now either we can define the name of the image that we want our service to use like
    # python image that we have already defined inside our docker file,
    # image: <image-name> # eg. image: python

    # or we can do the build which will build our image from the dockerfile, so the 
    # docker-compose will automatically build our image if it doesnt exists.
    # build: <path-to-dockerfile>
    build: .
    
    # As our apis depends on our postgres database, we can mention it here the name of the
    # services our backend_apis service depends on, so before running our backend_apis service
    # our postgres_database service will be executed first, and start the postgres_database 
    # container.
    # So this will tell the docker that I want to start the postgres_database container before
    # my backend_apis container starts.
    # NOTE:: As postgres instance may take time to load up put checks inside your code to handle 
    # that.
    depends_on:
      - postgres_database

    # We can mention the name to give to our container
    container_name: apis

    # Now we will specify the port that we want to open up so that the outside world can 
    # reach out to our container but remember our container is running inside another 
    # system i.e. server so we have to mention how the container talks with the requests
    # we receive at the server.
    ports:
      # Now we need to mention how the connection will be established between our host
      # machine and our container, i.e. when we receive requests on this, port-on-host
      # redirect that to this, port-on-container.
      #
      # port-on-container: whatever port our application is running on eg. 8000
      # port-on-host: could be any port our host machine is listening for our requests
      # from the outside world eg. 80,43,443 or 8000(in case we are using services like
      # ngnix to handle the outside requests)
      #
      # - <port-on-host>:<port-on-container>
      - 8000:8000

    # Setting up the environment variables related to our project, we have two options 
    # for Setting environment variables:
    #
    # manually Setting each environment variable and its value 
    # environment:
        # - <name>: <value>
    environment:
      - DATABASE_HOSTNAME=postgres_database 
      - DATABASE_PORT=5432
      - DATABASE_PASSWORD=password123 
      - DATABASE_NAME=mydb
      - DATABASE_USERNAME=postgres
      - SECRET_KEY=098ASDF8A709SD7F986A8D67F98ADS7F098789BU09FHDG890HJ8JHGKJK354HJ
      - ALGORITHM=HS256
      - ACCESS_TOKEN_EXPIRE_MINUTES=30

    # using a environment variables file, by mentioning its path
    # env_file:
        # - <filename> #eg. ./.env
  

    # Now, we will setup a docker container for our postgres database. 
    # Let's define our postgres database service:
  postgres_database:
    # We will use the official postgres image
    image: postgres

    # We have to define some environment variables for our database, these will be used
    # by docker to setup our postgres database:
    environment:
      - POSTGRES_PASSWORD=password123
      - POSTGRES_DB=mydb

    # Data persistence for postgres
    # To persist our data, such that it does not get deleted when the container is terminated
    # we need to use volumes, that's what allows us to save data from our container to our local
    # machine. So that if we kill a container we can spin up a new container and point that to
    # those files. 
    # There are difference kinds of volumes that we can use in docker, like Anonymous volumes,
    # named volumes, bind-mount volumes. 
    # We will use named volumes.
    volumes:
      - postgres-db:/var/lib/postgresql/data # <volume-name>:<path-in-the-container-where-postgres-will-write-to>

# This will take the data from the path postgres container used and paste it in docker managed local path 
# in Dockerâ€™s internal storage, usually under /var/lib/docker/volumes/ on Linux
# If we stop, restart, or even delete the postgres_database container, the postgres-db volume remains intact.
# when we spin up a new container with the same volume, Postgres finds its old data and continues as if nothing happened.
volumes:
  postgres-db:




# docker-compose commands:
# 
# > docker compose up -d # run the docker-compose file and create all the services in
#                        # detached mode, this will build the image if the image is 
#                        # already created previously it will not recrete it.
#                        # if we had made changes to our dockerfile and we want it to
#                        # build the new image we can use the --build flag to explicitly
#                        # command it to build the new image
# 
# > docker image ls # this will list all the available docker images 
#
# > docker ps # this will list all the running containers
# > docker ps -a # this will list all the avaibale containers running or not
#
# > docker compose down # to tear down everything
#
#
# Now to access our endpoints, just request on localhost:port to access it
#
